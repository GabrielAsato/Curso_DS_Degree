{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61d6231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8b3c9",
   "metadata": {},
   "source": [
    "### RNNs\n",
    "\n",
    "* Redes recorrentes são utilizadas para lidar com dados sequenciais, como por exemplo:\n",
    "  * Previsão de séries temporais;\n",
    "  * Reconhecimento de fala;\n",
    "  * Tradução de idiomas;\n",
    "  * Reconhecimento de ações em vídeo (como \"rapaz correndo\", \"moça tocando violão\");\n",
    "  * Geração de música;\n",
    "  * Problemas de genética, que envolvem sequenciamentos de DNAs\n",
    "  \n",
    "* Para lidar com esse tipo de dados, RNNs tradicionais utilizam uma estrutuar de neurônios de forma semelhante a uma MLP, adicionando uma estrutura de retroalimentação (como um loop) para aprender as informações de cada dado incrementalmente;\n",
    "\n",
    " ![Title](imgs/rnns.png) \n",
    " \n",
    "* Entretanto, essa estrutura não é muito eficiente para longas sequências devido a problemas do gradiente (vanish gradient)\n",
    "\n",
    "![Title](imgs/gradient_rnns.gif) \n",
    " \n",
    "* Redes LSTM, por outro lado, são redes recorrentes que filtram a entrada por meio de uma estrutura composta por gates e célula, de forma a reduzir os efeitos do gradiente para sequências maiores \n",
    "  *  Célula: conecta a entrada da célula a resposta de cada gate\n",
    "  * Gates: funções de ativação que vão analisar a entrada e filtrar o conhecimento que deverá ser esquecido temporariamente para compreender o dado atual (forget gate), conhecimento que deverá ser adicionado para compreender o dado atual (update gate) e output gate é a parte da rede responsável pela tarefa propriamente dita para gerar a saída do modelo\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6861f3c",
   "metadata": {},
   "source": [
    "### Leitura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df25e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000 ### tamanho do vocabulário\n",
    "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=max_features) \n",
    "### leitura da base de dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ac744c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dc125",
   "metadata": {},
   "source": [
    "### Visualizando as sentenças "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86aa49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = datasets.imdb.get_word_index() ### dicionário com cada palavra do vocabulario\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items()) ### pega chave e valor do dicionário para decodificar a sentença\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0]) ## desfaz a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c15eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75b8a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61a8a0",
   "metadata": {},
   "source": [
    "### Pré-processamento\n",
    "\n",
    "Uma rede neural, seja MLP, CNN ou RNNs, trabalham com entradas com duas características\n",
    "* Tamanho fixo\n",
    "* Entrada numérica\n",
    "\n",
    "Sendo assim, como pre-processamento inicial, deve-se verificar que essas duas características estão atendidas antes de implementar uma RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeec34ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de palavras\n",
    "len(x_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1fffafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200 ### tamanho maximo de cada amostra\n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen) ### aplica o padding\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "### sentenças menores que 200 vão ser preenchidas com zero, sentenças maiores que 200 caracteres terão seus caracteres eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcc69101",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_val, y_treino, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f434b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 200)\n",
      "(2500, 200)\n",
      "(25000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(x_treino.shape)\n",
    "print(x_val.shape)\n",
    "print(x_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc44ba",
   "metadata": {},
   "source": [
    "### Arquitetura de rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9844ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df63aed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treino.max() ### tamanho máximo de palavras no vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cf2b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   10,  693,  158],\n",
       "       [  24,   17,   78, ...,  251,  342,  158],\n",
       "       [   0,    0,    0, ...,  106,    5,  358],\n",
       "       ...,\n",
       "       [3137,    7,    6, ...,  736, 2929, 1359],\n",
       "       [  18,    4, 1047, ..., 8533,   23, 1092],\n",
       "       [   0,    0,    0, ..., 1681,  180,  133]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8948183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "704/704 [==============================] - 85s 114ms/step - loss: 0.4128 - accuracy: 0.8081 - val_loss: 0.2894 - val_accuracy: 0.8840\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 91s 129ms/step - loss: 0.2041 - accuracy: 0.9229 - val_loss: 0.3106 - val_accuracy: 0.8764\n"
     ]
    }
   ],
   "source": [
    "rnn = Sequential() ### define um modelo como sequencial (cada camada terá como entrada o resultado da camada anterior)\n",
    "\n",
    "rnn.add(Input(shape=(maxlen,))) ### define a entrada do modelo. A entrada é colocada de forma que cada amostra tenha o tamanho máximo definido anteriormente (200 caracteres)\n",
    "rnn.add(Embedding(max_features, 128)) ### embedding é formada passando o tamanho máximo de vocabulario (20000) e o tamanho do vetor de saida (128). Com isso cada palavra do vocabulario terá um vetor de 128 posições indicando a relação dela com as palavras do vocabulário\n",
    "\n",
    "rnn.add((LSTM(64))) ### cria uma lstm com 64 células\n",
    "rnn.add(Dense(64, activation=\"relu\")) ### cria uma camada completamente conectada de 64 neuronios e função de ativação relu\n",
    "rnn.add(Dense(1, activation=\"sigmoid\")) ### cria uma camada de saida para aclassificar o modelo\n",
    "rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"]) ### define a otimização da rede neural\n",
    "hist = rnn.fit(x_treino, y_treino, epochs=2, batch_size=32, validation_data=(x_val, y_val)) ### treina o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd02166",
   "metadata": {},
   "source": [
    "## Podemos utilizar mais de uma LSTM?\n",
    "\n",
    "Sim! Quanto mais complexo o problema, mais LSTMs precisamos!\n",
    "Sendo assim, é comum criarmos diferentes LSTMs, uma recebendo o resultado do processamento da outra.\n",
    "Para isso, basta colocarmos um rnn.add para o Keras e adicionar mais uma LSTM. Além disso, deverá setar o parâmetro return_sequences como True.\n",
    "\n",
    "#### O que é o return sequences?\n",
    "\n",
    "* Uma LSTM pode retornar tanto o processamento final dela (a resposta), como o aprendizado que teve\n",
    "* Para classificar, só é necessário a resposta da LSTM\n",
    "* Para utilizar duas LSTM em sequência, precisamos passar para a próxima LSTM os dois retornos, isso é feito utilizando o return_sequences\n",
    "\n",
    "#### LSTMs bidirecionais\n",
    "\n",
    "* Também podemos definir a LSTM de forma bidirecional\n",
    "* Uma LSTM bidirecional possui dois sentidos\n",
    "* Aprende a palavra atual baseado no contexto passado\n",
    "* Aprende a palavra atual baseado no contexto do futuro \n",
    "* Útil em casos que a resposta está apenas mais a frente da frase. Por exemplo, quando sujeito e predicado estão invertidos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c830a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/2\n",
      "704/704 [==============================] - 229s 321ms/step - loss: 0.3923 - accuracy: 0.8207 - val_loss: 0.2838 - val_accuracy: 0.8868\n",
      "Epoch 2/2\n",
      "704/704 [==============================] - 240s 341ms/step - loss: 0.2060 - accuracy: 0.9223 - val_loss: 0.3648 - val_accuracy: 0.8648\n"
     ]
    }
   ],
   "source": [
    "rnn = Sequential()\n",
    "\n",
    "rnn.add(Input(shape=(maxlen,)))\n",
    "rnn.add(Embedding(max_features, 128))\n",
    "\n",
    "rnn.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "rnn.add((LSTM(64)))\n",
    "rnn.add(Dense(64, activation=\"relu\"))\n",
    "rnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "hist = rnn.fit(x_treino, y_treino, epochs=2, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1191a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 48s 61ms/step - loss: 0.3863 - accuracy: 0.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3862696886062622, 0.8515599966049194]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rnn.evaluate(x_teste, y_teste, verbose=1) ### faz uma avaliação geral do modelo indicando a loss e a acc\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94f42501",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rnn.predict(x_teste) #### retorna todas as predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "698251c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2644105 ],\n",
       "       [0.99584997],\n",
       "       [0.96135825],\n",
       "       ...,\n",
       "       [0.1864289 ],\n",
       "       [0.12678808],\n",
       "       [0.9022596 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred ### saída não binária, necessário converter para 0 e 1 igual o y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90d1e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d34adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84     12500\n",
      "           1       0.81      0.92      0.86     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.86      0.85      0.85     25000\n",
      "weighted avg       0.86      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred.round())) ### desempenho do modelo com sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab68ad",
   "metadata": {},
   "source": [
    "### Exemplo IDMB em raw - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04b2b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/7csz5lt17fs3dd7hl2vvgns00000gn/T/ipykernel_9654/3060947599.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('../datasets/sentiment labelled sentences/imdb_labelled.txt', error_bad_lines=False, delimiter='\\t', header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../datasets/sentiment labelled sentences/imdb_labelled.txt', error_bad_lines=False, delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cff03adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "0    A very, very, very slow-moving, aimless movie ...  0\n",
       "1    Not sure who was more lost - the flat characte...  0\n",
       "2    Attempting artiness with black & white and cle...  0\n",
       "3         Very little music or anything to speak of.    0\n",
       "4    The best scene in the movie was when Gerardo i...  1\n",
       "..                                                 ... ..\n",
       "743  I just got bored watching Jessice Lange take h...  0\n",
       "744  Unfortunately, any virtue in this film's produ...  0\n",
       "745                   In a word, it is embarrassing.    0\n",
       "746                               Exceptionally bad!    0\n",
       "747  All in all its an insult to one's intelligence...  0\n",
       "\n",
       "[748 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df648e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[0]\n",
    "y = df[1]\n",
    "sentences_train, sentences_val, y_train, y_val = train_test_split(x, y, test_size = 0.1, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57591cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  \n",
      "[29, 28, 170, 442, 1055, 1056, 2, 635, 1057, 50, 5, 32, 636, 27, 1, 39]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=20000) ### cria o tokenizador indicando que o vocabulário será composto por 20000 palavras\n",
    "tokenizer.fit_on_texts(sentences_train) ### passa as palavras para frequencia\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train) ### fita no treino\n",
    "X_val = tokenizer.texts_to_sequences(sentences_val) ### fita no teste\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "\n",
    "print(sentences_train[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71caae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 1\n",
      "all: 27\n"
     ]
    }
   ],
   "source": [
    "for word in ['the', 'all']:\n",
    "    print('{}: {}'.format(word, tokenizer.word_index[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "022f0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 200\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen) ### faz o padding\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23ca682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/2\n",
      "22/22 [==============================] - 11s 333ms/step - loss: 0.0000e+00 - accuracy: 0.4889 - val_loss: 0.0000e+00 - val_accuracy: 0.4800\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 7s 331ms/step - loss: 0.0000e+00 - accuracy: 0.4844 - val_loss: 0.0000e+00 - val_accuracy: 0.4800\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "rnn = Sequential()\n",
    "\n",
    "rnn.add(Input(shape=(maxlen,)))\n",
    "rnn.add(Embedding(max_features, 128))\n",
    "\n",
    "rnn.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "rnn.add(Bidirectional(LSTM(64)))\n",
    "rnn.add(Dense(64, activation=\"relu\"))\n",
    "rnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "hist = rnn.fit(X_train, y_train, epochs=2, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad589f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
