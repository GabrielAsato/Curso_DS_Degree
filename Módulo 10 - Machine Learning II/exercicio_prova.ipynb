{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e0516d",
   "metadata": {},
   "source": [
    "# Preparação para a Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb94c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"\"\"\n",
    "{} - Pensando no algoritimo de Machine Learning \\\"{}\\\" responda:\n",
    "a) Resumidamente como ele funciona?\n",
    "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
    "c) E suas fraquezas?\n",
    "d) Como é seu método de avaliação?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a328fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_algoritmos = [\n",
    "    'SVM',\n",
    "    'SVR',\n",
    "    'AdaBoosting',\n",
    "    'GradientBooting',\n",
    "    'XGBoosting',\n",
    "    'K-Means',\n",
    "    'DBScan',\n",
    "    'Agglomerative Clustering'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9514a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 - Pensando no algoritimo de Machine Learning \"SVM\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n",
      "\n",
      "2 - Pensando no algoritimo de Machine Learning \"SVR\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n",
      "\n",
      "3 - Pensando no algoritimo de Machine Learning \"AdaBoosting\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n",
      "\n",
      "4 - Pensando no algoritimo de Machine Learning \"GradientBooting\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n",
      "\n",
      "5 - Pensando no algoritimo de Machine Learning \"XGBoosting\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n",
      "\n",
      "6 - Pensando no algoritimo de Machine Learning \"K-Means\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n",
      "\n",
      "7 - Pensando no algoritimo de Machine Learning \"DBScan\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n",
      "\n",
      "8 - Pensando no algoritimo de Machine Learning \"Agglomerative Clustering\" responda:\n",
      "a) Resumidamente como ele funciona?\n",
      "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
      "c) E suas fraquezas?\n",
      "d) Como é seu método de avaliação?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, nome_algoritmo in enumerate(nomes_algoritmos, start=1):\n",
    "    print(pergunta.format(i, nome_algoritmo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3055f04",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356811d",
   "metadata": {},
   "source": [
    "1 - Pensando no algoritimo de Machine Learning \"SVM\" responda:\n",
    "\n",
    "a) **Resumidamente como ele funciona?** Support Vector Machine (SVM) é um algoritmo de aprendizado supervisionado muito usado para classificação, mas pode ser usado para regressão. A ideia principal é, baseado nos dados de treino, tenta achar o **hiperplano ótimo** na qual pode usar para classificar novos pontos de dados (test dataset). Em uma dimensão, o **hiperplano** é um ponto, e em duas dimensões é uma linha. O hiperplano são limites de decisão que classificam o conjunto de dados enquanto maximizam a margem.   \n",
    "    A função que classifca é chamada de **kernel**, que calcula basicamente a distância entre duas observações. O SVM localiza esse \"hiperplano\" para maximizar a margem (largura ou espessura do hiperplano, ou a distância normal entre os vetores de suporte e o hiperplano) entre os vetores de suporte (pontos mais próximos ao hiperplano) das duas classes.\n",
    "    O melhor hiperplano capaz de separar duas classes estaria localizado no ponto médio entre eles (maximizando a margem), trazendo uma certa característica de simetria ma classificação, onde o ponto mais próximo de cada classe está a uma distância d (meia margem) do hiperplano, de forma a minimizar erros de classificação e problemas de enviesamento (bias) do modelo (overfitting).\n",
    "    Quando os dadods não são linearmente separáveis, não podemos desenhar uma linha reta para separar as duas classes. Para resolver o problema, usamos dados não linearmente separáveis no espaço n-dimensional. Transforme-o em um espaço dimensional mais alto para torná-lo linearmente separável. \n",
    "\n",
    "b) **Quais são suas forças, o que o difere dos outros algoritmos?**\n",
    "    - Trabalha bem em espaços de alta dimensão\n",
    "    - Eficaz nos casos em que o número de dimensões é maior que o número de amostras\n",
    "    - Sempre busca o mínimo global\n",
    "    - Utilizado para dados separáveis linearmente e não linearmente separáveis\n",
    "    - é eficiente porque utiliza apenas os dados dos vetores de suporte\n",
    "    - Usado para detectar outliers\n",
    "\n",
    "c) **E suas fraquezas?**\n",
    "    - Tempo de treinamento é alto se existe muitos dados\n",
    "    - Interpretação e visualização do modelo é extremamente complexa\n",
    "    - Não funciona muito bem quando o conjunto de dados tem mais ruído, ou seja, as classes de destino estão sobrepostas.\n",
    "    - Escolhas indevidas de hiperparâmetros **C** e **Gamma** podem levar a overfitting (Usar RandomSearchCV ou GridSearchCV)\n",
    "\n",
    "d) **Como é seu método de avaliação?**\n",
    "    - Utilizamos métodos de avaliação de classificação\n",
    "        - Classification report\n",
    "            - Precision\n",
    "            - Recall\n",
    "            - F1 score\n",
    "            - Accuracy\n",
    "        - Confusion matrix\n",
    "\n",
    "--\n",
    "- https://medium.com/@msremigio/m%C3%A1quinas-de-vetores-de-suporte-svm-77bb114d02fcv\n",
    "- https://www.linkedin.com/pulse/introdu%C3%A7%C3%A3o-ao-svm-como-classificador-rodrigo-araujo-\n",
    "- https://towardsdatascience.com/svm-and-kernel-svm-fed02bef1200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337cf5d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ae655",
   "metadata": {},
   "source": [
    "2 - Pensando no algoritimo de Machine Learning \"SVR\" responda:\n",
    "\n",
    "a) **Resumidamente como ele funciona?**\n",
    "    Da mesma forma vista em SVM, os elementos de classificação também são relevantes aqui. A utilização do kernel para que um modelo de regressão linear seja treinado no espaço de features. No espaço, de inputs, este modelo é refletido como uma regressão **não-linear**. A principal diferença é que o conceito de margem também está presente, de modo que apenas alguns pontos efetivamente vão construir para regressão. Neste caso, são pontos dentro da margem (região conhecida como e-tubo) que serão estes vetores de suporte, ou seja, os pontos fora da margem não contribuem para a função custo.\n",
    "     SVR fornece uma flexibilidade em definir o quanto os erros são aceitáveis no modelo e encontrar o hiperplano apropriado que fita os dados. Em comparação com OLS, a Função Objetiva do SVR é minimizar os coeficientes -mais especificamente, a norma L2 do vetor de coeficientes- não o erro quadrado. O erro é analisado na restrição, onde calculamos o erro absoluto seja menor ou igual a margem, chamado de máximo epslon. Podemos tunar o epslon para atingir a acurácia do modelo.\n",
    "    Em outras palavras, minimizar:\n",
    "             $$min \\frac{1}{2}*\\|w\\|^2$$\n",
    "    E restringir:\n",
    "            $$|y_i-w_i*x_i|\\leq\\epsilon$$\n",
    "        \n",
    "b) **Quais são suas forças, o que o difere dos outros algoritmos?**\n",
    "    - é robusto contra outliers\n",
    "    - O modelo decisão pode ser atualizado facilmente\n",
    "    - Tem uma excelente capacidade de generalização, com grande acurácia\n",
    "    - Facilmente implementado\n",
    "    \n",
    "c) **E suas fraquezas?**\n",
    "    - Não é recomendado para datasets grandes\n",
    "    - Em um caso onde o número de features excede o número de dados, o SVM não performará bem.\n",
    "    - Assim como em SVM, não performa bem com ruído, ou seja, dados sobrepostos.\n",
    "    \n",
    "d) **Como é seu método de avaliação?**\n",
    "    - Mesma métricas de regressão como r2_score\n",
    "\n",
    "--\n",
    "- https://towardsdatascience.com/an-introduction-to-support-vector-regression-svr-a3ebc1672c2\n",
    "- https://towardsdatascience.com/unlocking-the-true-power-of-support-vector-regression-847fd123a4a0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad695c42",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdfb8f2",
   "metadata": {},
   "source": [
    "3 - Pensando no algoritimo de Machine Learning \"AdaBoosting\" responda:\n",
    "\n",
    "a) **Resumidamente como ele funciona?**\n",
    "    O Adaboost significa Adaptative Boosting e tem como procedimento geral a criação de sucessiva dos chamados \"weak learners\" que são modelos fracos de aprendizagem (no caso de árovores decisão, são stumps). O Adaboost utiliza os erros da árvore anterior para melhorar a próxima árvore. As predições finais são feitas com base nos **pesos de cada stump**. O método começa treinando um classificador fraco no **dataset original**, e depois treina diversas cópias adicionais do classificador **no mesmo dataset**, mas dando **um peso maior às observações que foram classificadas erroneamente** (nos casos de regressão, as observações com maior erro).\n",
    "    Inicialmente, todas as amostras tem pesos iguais. A medida que o algoritmo avança, os pesos das amostras classificadas incorretamente são incrementadas. Um stump com uma feature é construído e calcula-se o erro total (ou seja, a soma dos pesos classifcadas erradas). Em seguida, calcula-se o novo peso (alfa) como:\n",
    "    $$\\alpha = \\eta * \\frac{1-erroTotal}{erroTotal}$$\n",
    "    Onde\n",
    "    $$erroTotal = \\sum{pesosErrados}$$\n",
    "    Em seguida, atualizam os pesos:\n",
    "    $$novopeso = pesoAnterior * e^\\alpha$$\n",
    "    se classificou de maneira errada e\n",
    "    $$novopeso = pesoAnterior * e^{-\\alpha}$$\n",
    "    se classificou de maneira correta\n",
    "    Ou seja, aumenta-se o peso para classificação errada e diminui para as certas. Outro fator é que a soma dos pesos devem somar 1, por isso, **precisa ser normalizado**.\n",
    "    Um novo dataset é montado e aqueles com maiores pesos tem mais chance de surgirem nesse dataset. Os passos de criar o stump até a criação de um novo dataset com maiores pesos é repetido até o número de iterações do hiperparâmetro.\n",
    "    \n",
    "b) **Quais são suas forças, o que o difere dos outros algoritmos?**\n",
    "    - Pode ser usado tanto para classificaçõs como para regressões\n",
    "    - Lida bem com dados diferentes\n",
    "    - Modelo resistente a outliers caso usada a Função de Perda apropriada\n",
    "    \n",
    "c) **E suas fraquezas?**\n",
    "    - Não pode ser paralelizado (não é escalável)\n",
    "    - Risco de overfitting\n",
    "    - Ajuste de parâmetros é mais difícil\n",
    "    \n",
    "d) **Como é seu método de avaliação?**\n",
    "    Mesmos métodos de avaliação para Classificação\n",
    "\n",
    "--\n",
    "https://pedroazambuja.medium.com/adaboost-adaptive-boosting-dbbec150fced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3ee90",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f3052",
   "metadata": {},
   "source": [
    "4 - Pensando no algoritimo de Machine Learning \"GradientBooting\" responda:\n",
    "\n",
    "a) **Resumidamente como ele funciona?**\n",
    "    O gradient boosting também é baseado no método de boosting (usar weak learners em sequência para minimizar os erros cometidos). Neste caso, o boosting é implementado através de um **gradiente** explícito. A ideia é caminhar na direção do erro mínimo de maneira iterativa. Esse caminho se dá pelo **gradiente da função de custo/perda**, que mede os erros cometidos.\n",
    "    O objetivo geral do método é: determinar quais são os **parâmetros** da hipótese que minimizam a função custo/perda.\n",
    "    A função custo/perda (*loss*) é explicitamente minimizada por um procedimento de gradiente. E o gradiente está relacionado com o procedimento de **encadeamento progressivo de weak learners**.\n",
    "    Os principais hiperparâmetros são: n_etimators (número de weak learners) e learning_rate (constante que multiplica o gradiente descendente (~0.1)).\n",
    "    O algoritmo funciona do seguinte modo:\n",
    "- um valor $F_0(x)$ é criado a partir da minimização da função de custo/perda.\n",
    "- Em seguida, o residuo ($r_n$) é calculado a partir da derivada da função custo/perda em relação ao valor predito\n",
    "- Esse valor é computado.\n",
    "- Ao criar um stump, colocar em cada lado o resíduo de acordo com a decisão da árvore.\n",
    "- Calcular $\\gamma_{ij}$ que minimiza os valores de $R_{ij}= [r_1, r_2, ...]$\n",
    "- Atualizar o valor de $F_M(x) = F_{M-1}(x) + \\eta * \\sum{\\gamma_{ij}}$\n",
    "        \n",
    "b) **Quais são suas forças, o que o difere dos outros algoritmos?**\n",
    "\n",
    "- ótima precisão de previsão\n",
    "- Otimização com diferentes funções de perda (precisa ser diferenciável) e vários ajustes de hiperparâmetros\n",
    "- Não precisa de muito pré processamento\n",
    "- Lida bem com dados faltantes, não é necessário imputação\n",
    "    \n",
    "c) **E suas fraquezas?**\n",
    "- Facilmente pode ter overfitting\n",
    "- Alto custo computacional\n",
    "- Devido a alta quantidade de hiperparâmetros, necessita de um GridSearchCV muito grande\n",
    "- Muito difícil a interpretação\n",
    "\n",
    "d) **Como é seu método de avaliação?**\n",
    "      Mesmo método para avaliação de regressão ou classificação\n",
    "   \n",
    "--\n",
    "https://medium.com/equals-lab/uma-breve-introdu%C3%A7%C3%A3o-ao-algoritmo-de-machine-learning-gradient-boosting-utilizando-a-biblioteca-311285783099\n",
    "! https://towardsdatascience.com/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502\n",
    "https://blog.paperspace.com/gradient-boosting-for-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d35af",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331eeb4",
   "metadata": {},
   "source": [
    "5 - Pensando no algoritimo de Machine Learning \"XGBoosting\" responda:\n",
    "\n",
    "a) Resumidamente como ele funciona?\n",
    "\n",
    "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
    "\n",
    "c) E suas fraquezas?\n",
    "\n",
    "d) Como é seu método de avaliação?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f8d7a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1974de9",
   "metadata": {},
   "source": [
    "6 - Pensando no algoritimo de Machine Learning \"K-Means\" responda:\n",
    "\n",
    "a) Resumidamente como ele funciona?\n",
    "\n",
    "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
    "\n",
    "c) E suas fraquezas?\n",
    "\n",
    "d) Como é seu método de avaliação?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d845620",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e0876",
   "metadata": {},
   "source": [
    "7 - Pensando no algoritimo de Machine Learning \"DBScan\" responda:\n",
    "\n",
    "a) Resumidamente como ele funciona?\n",
    "\n",
    "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
    "\n",
    "c) E suas fraquezas?\n",
    "\n",
    "d) Como é seu método de avaliação?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f989e36d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5fd5b",
   "metadata": {},
   "source": [
    "8 - Pensando no algoritimo de Machine Learning \"Agglomerative Clustering\" responda:\n",
    "\n",
    "a) Resumidamente como ele funciona?\n",
    "\n",
    "b) Quais são suas forças, o que o difere dos outros algoritmos?\n",
    "\n",
    "c) E suas fraquezas?\n",
    "\n",
    "d) Como é seu método de avaliação?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca130de",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627ee5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
