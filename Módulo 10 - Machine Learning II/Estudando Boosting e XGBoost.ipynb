{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748d5baa-2c76-465b-a03f-66fce9b6e9e4",
   "metadata": {},
   "source": [
    "## Boosting e XGBoost (aula02 e aula03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e58627-c92b-46d4-afc0-49234722cea5",
   "metadata": {},
   "source": [
    "A metodologia  foi criada, inicialmente, para resolver uma classificação. A ideia principal é encontrar hipóteses fracas, aprender repetidamente e combinar essas hipóteses fracas dentro de uma única hipótese.\n",
    "É considerada um método de ensemble. O método Ensemble tem como objetivo **combinar as predições de diversos estimadores mais simples** para gerar uma predição final mais robusta.\n",
    "- Métodos de Boosting têm como procedimento geral a construção de estimadores de forma sequencial, de modo que estimadores posteriores tentam reduzir o viés do estimador conjunto, que leva em consideração estimadores anteriores. Ex.: **adaboost**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ad185-7527-411a-8c98-045478b2ce20",
   "metadata": {},
   "source": [
    "### Método de Ensemble\n",
    "\n",
    "Os métodos de Ensemble que tem como objetivo **combinar as predições de diversos estimadores mais simples** para gerar uma **predição final mais robusta**. Os métodos de ensemble costumam ser divididas em duas classes:\n",
    "- **Métodos de média:** têm como procedimento geral construir diversos estimadores independentes, e tomar a média de suas predições como a predição final. O principal objetivo do método é reduzir **variância**, de modo que o modelo final seja melhor que todos os modelos individuais. Ex.: RnadomForest\n",
    "- **Métodos de boosting:** têm como procedimento geral a construção de estimadores de forma sequencial, de modo que estimadores posteriores tentam reduizr o **viés** do estimador conjunto, que leva em consideração estimadores anteriores. Ex.: adaboost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a5344-8b94-4bc0-85c5-900b3a347579",
   "metadata": {},
   "source": [
    "### Bagging vs Boosting\n",
    "\n",
    "- **Bagging**: Paralelo\n",
    "- **Boosting**: Sequencial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ac47a-ad1e-4a8a-81a0-1a67bacbcc40",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "\n",
    "Significa **Adaptative Boosting**, e tem como procedimento geral **a criação sucessiva dos chamados weak learners**, que são models bem fracos de aprendizagem - geralmente, **árvores de um único nó (stumps)**\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1744/1*nJ5VrsiS1yaOR77d4h8gyw.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b6e78-7d41-4e16-8fd2-d1310c407653",
   "metadata": {},
   "source": [
    "O AdaBoost utiliza os erros da árvore anterior para melhorar a próxima árvore. As predições finais são feitas com base nos pesos de cada stump, cusa determinação faz parte do algoritmo.\n",
    "\n",
    "Aqui, o bootstrapping não é utilizado. O método começa treinando um classificador fraco no dataset original, e depois treina diversas cópias adicionais do classificador no mesmo dataset, mas dando um peso maior às observações que foram classificados erroneamente (ou, no caso de regressões, a observações **com o maior erro**).\n",
    "\n",
    "Assim, após diversas iterações, classificadores / regressores vão sequencialmente \"focando nos casos mais difíceis\", e construindo um classificador encadeado que seja forte, apesar de utilizar diversos classificadores fracos como elementos fundamentais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0f6e3-7685-43f0-a897-f8fcc0614a60",
   "metadata": {},
   "source": [
    "Único hiperparâmetro é n_estimators que é o número de weak learners encadeados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07200136-c7bc-4d87-bba0-5b5b7695b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b18b194-7d2a-474d-9c62-1a574d51c284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
       "0   67    male    2     own             NaN           little           1169   \n",
       "1   22  female    2     own          little         moderate           5951   \n",
       "2   49    male    1     own          little              NaN           2096   \n",
       "3   45    male    2    free          little           little           7882   \n",
       "4   53    male    2    free          little           little           4870   \n",
       "\n",
       "   Duration              Purpose  Risk  \n",
       "0         6             radio/TV  good  \n",
       "1        48             radio/TV   bad  \n",
       "2        12            education  good  \n",
       "3        42  furniture/equipment  good  \n",
       "4        24                  car   bad  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/german_credit_data.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6917c6f-a0ee-49e3-ab20-b7663f4feb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_test_split\n",
    "X = df.drop(columns = [\"Risk\"])\n",
    "y = df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c87a070-899c-4ccc-a780-3ca8f6d7d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação de tipos de variáveis\n",
    "num_cols = X_train.select_dtypes(\"number\").columns\n",
    "cat_cols = X_train.select_dtypes(exclude = \"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4a5cd3-c324-4ae0-a46f-e742c283846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento\n",
    "\n",
    "# Impute | Transform\n",
    "num_features = Pipeline([\n",
    "    (\"imputer_num\", SimpleImputer(strategy = 'mean')),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Impute | Transform\n",
    "cat_features = Pipeline([\n",
    "    (\"imputer_cat\", SimpleImputer(strategy = 'constant', fill_value='unknown')),\n",
    "    (\"ohe\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "# preprocessamento do Impute | Transform\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"transf_num\", num_features, num_cols),\n",
    "    (\"transf_cat\", cat_features, cat_cols)\n",
    "])\n",
    "\n",
    "# Rodar o modelo\n",
    "pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", AdaBoostClassifier(random_state = 42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32fa23d-dff6-4137-8ac9-7697296f5621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('transf_num',\n",
       "                                                  Pipeline(steps=[('imputer_num',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['Age', 'Job', 'Credit amount', 'Duration'], dtype='object')),\n",
       "                                                 ('transf_cat',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(fill_value='unknown',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  Index(['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose'], dtype='object'))])),\n",
       "                ('model', AdaBoostClassifier(random_state=42))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitar o pipe\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3dd4b7-0438-456e-8736-dea48ebf5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c98def-8212-40fa-a4fb-cee2d6f7bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.48      0.54        60\n",
      "        good       0.80      0.87      0.83       140\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.68      0.69       200\n",
      "weighted avg       0.74      0.76      0.75       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c3a24-fd67-4ecb-a47a-9e7665931f69",
   "metadata": {},
   "source": [
    "### Gradient boosting\n",
    "\n",
    "Existem outras classes de ensemble, em particular uma que usa o **gradient boosting**, que é baseado na utilização de weak learners sequencialmente adicionados de modo a **sequencialmente minimizar os erros cometidos**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93dd96-5222-4a33-b38a-416e94207a5d",
   "metadata": {},
   "source": [
    "O objetivo geral do método é bem simples: determinar quais são os **parâmetros** da hipótese que minimizam a função de custo/perda. Para isso, o método \"percorre\" a função de erro, indo em direção ao seu mínimo (este caminho feito na função se dá justamente pela **determinação iterativa dos parâmetros**, isto é, **a cada passo, chegamos mais perto dos parâmetros finais da hipótese**, conforme eles são ajustados aos dados.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6191b7-c274-4ab6-bccf-a0b150c4122f",
   "metadata": {},
   "source": [
    "Os principais hiperparâmetros a serem ajustados são:\n",
    "- n_estimators: novamente, o número de weak learners encadeados\n",
    "- learning_rate: a constante que multiplica o gradiente no fradiente descendente. Essencialmente, controla o \"tamanho do passo\" a ser dado em direção ao mínimo (recomendado <= 0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7199115c-6337-4744-b2bb-37f82434b279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('transf_num',\n",
       "                                                  Pipeline(steps=[('imputer_num',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['Age', 'Job', 'Credit amount', 'Duration'], dtype='object')),\n",
       "                                                 ('transf_cat',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(fill_value='unknown',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  Index(['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose'], dtype='object'))])),\n",
       "                ('gb_model', GradientBoostingClassifier(random_state=42))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipe_gb = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"gb_model\", GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14480271-33dc-4804-86b7-5a07868cf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be6439d-c0e1-4688-b13c-21417fb406a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.48      0.54        60\n",
      "        good       0.80      0.87      0.83       140\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.68      0.69       200\n",
      "weighted avg       0.74      0.76      0.75       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553623c7-8a6e-4235-9a71-e2327c0ddea2",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a64296-1d9d-4408-8bef-e111cb9a6965",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41506732-103a-43af-af47-1964dc3e0ab1",
   "metadata": {},
   "source": [
    "é o último modelo de Ensemble. Este método é um gradient boosting, com modificações que deixam mais 'extreme'.\n",
    "- Adição de regularização (L1 e L2) que melhora a capacidade de generalização\n",
    "- Usa derivadas de segunda ordem para o gradiente\n",
    "- A construção sequencial é paralelizada\n",
    "- Poda da árvore\n",
    "- Otimização de hardware\n",
    "- Regulariza por Lasso e Ridge\n",
    "- Trata valores faltantes, já \"aprende\" qual o melhor valor para adotar\n",
    "- Aplica quantil ponderado nos dados\n",
    "- Validação cruzada integrado\n",
    "\n",
    "Ref:\n",
    "https://medium.com/analytics-vidhya/what-makes-xgboost-so-extreme-e1544a4433bb\n",
    "https://xgboost.readthedocs.io/en/latest/tutorials/model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89238826-3524-40f0-93e0-5b0b011650ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48a6d90a-75b2-4c8f-93f4-358a2aa0dc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
       "0   67    male    2     own             NaN           little           1169   \n",
       "1   22  female    2     own          little         moderate           5951   \n",
       "2   49    male    1     own          little              NaN           2096   \n",
       "3   45    male    2    free          little           little           7882   \n",
       "4   53    male    2    free          little           little           4870   \n",
       "\n",
       "   Duration              Purpose  Risk  \n",
       "0         6             radio/TV  good  \n",
       "1        48             radio/TV   bad  \n",
       "2        12            education  good  \n",
       "3        42  furniture/equipment  good  \n",
       "4        24                  car   bad  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/german_credit_data.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba6a206a-f2cc-4bff-80d1-ce74d1fd9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features de target\n",
    "X = df.drop(columns = [\"Risk\"])\n",
    "y = df[\"Risk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40769184-e6ff-4f3d-9a2c-c4e0e4bfd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1625f2b8-f7f8-4f90-b0e2-3a4f68e90202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletar colunas numéricas e categóricas\n",
    "num_cols = X_train.select_dtypes('number').columns\n",
    "cat_cols = X_train.select_dtypes(exclude = 'number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06648d86-fe97-498e-a042-ef8dc137a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_features = Pipeline([\n",
    "    (\"ohe\", OneHotEncoder())\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"transf_cat\", cat_features, cat_cols)\n",
    "])\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"xgb\", XGBClassifier(learning_rate = 0.1, eval_metric = \"logloss\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4fdcbded-c02c-4ede-8549-9e30595f489f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('transf_cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  Index(['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose'], dtype='object'))])),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, eval_metric='logloss',\n",
       "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=6,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ab266b98-2dcd-431a-8695-8fbc7f5663ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pipe_xgb.predict(X_train)\n",
    "y_pred_test = pipe_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90047ff6-d8a2-4c13-b1f8-2a6470e1e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.84      0.72      0.78        58\n",
      "        good       0.89      0.94      0.92       142\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.87      0.83      0.85       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.45      0.38      0.41       242\n",
      "        good       0.75      0.80      0.77       558\n",
      "\n",
      "    accuracy                           0.67       800\n",
      "   macro avg       0.60      0.59      0.59       800\n",
      "weighted avg       0.66      0.67      0.66       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc87c0-9ed4-44d1-9b02-d6d0c0396eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
