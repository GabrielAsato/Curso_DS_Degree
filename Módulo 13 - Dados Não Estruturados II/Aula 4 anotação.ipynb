{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ec455e-e992-43f5-9a0f-3df7f4531233",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glove-python-binary\n",
      "  Downloading glove_python_binary-0.2.0-cp38-cp38-win_amd64.whl (244 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from glove-python-binary) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from glove-python-binary) (1.20.1)\n",
      "Installing collected packages: glove-python-binaryNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for retrying: [Errno 2] No such file or directory: 'c:\\\\users\\\\gabri\\\\anaconda3\\\\lib\\\\site-packages\\\\retrying-1.3.3.dist-info\\\\METADATA'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully installed glove-python-binary-0.2.0\n"
     ]
    }
   ],
   "source": [
    "#pip install glove-python-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08024864-8504-4ef1-bf5f-c98cec2e108d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Installing collected packages: Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.23\n",
      "    Uninstalling Cython-0.29.23:\n",
      "      Successfully uninstalled Cython-0.29.23\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for retrying: [Errno 2] No such file or directory: 'c:\\\\users\\\\gabri\\\\anaconda3\\\\lib\\\\site-packages\\\\retrying-1.3.3.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71de3d-e504-4c38-b6b8-335bba3aa009",
   "metadata": {},
   "source": [
    "## Aula 4 - Word Embedding\n",
    "\n",
    "As técnicas de Bag of Words baseiam-se simplesmente na **contagem e frequência das palavras**, o que perde boa parte da riqueza linguistica e semântica das frases, que são fundamentais para interpretação e análise destes textos.\n",
    "\n",
    "Para tratar a semântica dos textos, será introduzida a técnica de **Word Embeddings**, que consiste em uma ferramenta que transforma os textos levando em consideração todo o contexto analisado e, por fim, montando um mapa de características que determinada palavra pssa representar utilizando um vetor multidimensional.\n",
    "\n",
    "Utilizaremos dois modelos bem populares: **Word2Vec** e **GloVe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ac79c-147a-40e3-9efa-275212ba5737",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386d2b3e-8a82-48d5-9f2e-1b9d47c801af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "\n",
    "# Word2Vec : Redes Neurais (CBOW e Skip-Gram)\n",
    "# CBOW : fazer a previsão de uma palavra central a partir das minhas palavras na vizinhança\n",
    "# \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Hoje vai chover pela manhã\n",
    "# ([Hoje, chover], vai)\n",
    "# ([vai, pela], chover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291be2d1-218b-47af-a783-5c3e39fdf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "#model = Word2Vec(sentences,    # Conjunto de documentos para analisar\n",
    "#                min_count = 2) # Número mínimo de ocorrências para ser considerado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31090eb2-85c3-48ac-a5e8-c0fdb7075d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec([['ola','eu', 'me', 'chamo', 'joao'],\n",
    "                  ['hoje', 'estou', 'com', 'calor'],\n",
    "                  ['cansei', 'de', 'acordar', 'na', 'madrugada']], min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e8b09ec-8c3a-4d17-a895-aa89b5c779ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As primeiras três palavras: ['madrugada', 'na', 'acordar', 'de', 'cansei', 'calor', 'com', 'estou', 'hoje', 'joao', 'chamo', 'me', 'eu', 'ola']\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.index_to_key)\n",
    "print(f\"As primeiras três palavras: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d865bd07-6c15-47f5-a5c8-25d37bc8850a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ola', 0.2529045641422272),\n",
       " ('acordar', 0.17017902433872223),\n",
       " ('eu', 0.15016484260559082),\n",
       " ('calor', 0.13887983560562134),\n",
       " ('com', 0.03476494923233986),\n",
       " ('na', 0.004503009375184774),\n",
       " ('me', -0.005916213616728783),\n",
       " ('madrugada', -0.027750369161367416),\n",
       " ('estou', -0.028491009026765823),\n",
       " ('de', -0.04461336135864258)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('cansei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a39dff4c-9bea-42e3-b0f5-aac0a1468bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12348268,  0.02146596, -0.12413479, -0.03882489,  0.06433234,\n",
       "        0.10089482,  0.02072481,  0.03637067, -0.07109694,  0.1249757 ,\n",
       "       -0.10909214,  0.08038231, -0.14217989,  0.03522452, -0.08608747,\n",
       "       -0.07347176, -0.05377575,  0.09781744,  0.10029422, -0.0860459 ,\n",
       "        0.01337619, -0.14695045,  0.13508527,  0.16012223, -0.04743373,\n",
       "        0.01384137,  0.01291473,  0.09475029, -0.14885831,  0.01010924,\n",
       "        0.11881954,  0.0385996 ,  0.01945337, -0.16124423,  0.14671846,\n",
       "       -0.10834987, -0.05175874,  0.06043159, -0.01336407,  0.02441091,\n",
       "        0.03082287, -0.11811865, -0.16820891,  0.1563739 ,  0.10720698,\n",
       "       -0.11957207,  0.05886963,  0.00356424,  0.08222495, -0.12315281,\n",
       "        0.06965373,  0.07519705,  0.1722314 , -0.07738176, -0.02402995,\n",
       "       -0.12656683, -0.1677422 , -0.15706012, -0.01769049, -0.11248664,\n",
       "        0.08388515, -0.10661842,  0.04357405,  0.01279002, -0.0586737 ,\n",
       "       -0.01693751,  0.1726077 ,  0.1581953 , -0.07717573,  0.157108  ,\n",
       "       -0.0975849 ,  0.10258644, -0.05357223,  0.05935859,  0.05218858,\n",
       "        0.11935644, -0.04106078,  0.15178075,  0.13127342, -0.16514449,\n",
       "       -0.13851705, -0.13211177,  0.05056323, -0.04833999, -0.11985909,\n",
       "       -0.1405936 ,  0.14372285,  0.03442922, -0.16134559, -0.08289903,\n",
       "        0.05425576, -0.08152375,  0.09134211, -0.07322532,  0.04569481,\n",
       "       -0.13916528,  0.10741165,  0.08335172,  0.01361595,  0.05212322],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector(\"cansei\", norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca147495-1bc3-4ad0-814b-960b5859c13e",
   "metadata": {},
   "source": [
    "### Glove\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec9dd81b-be12-4957-89de-1e3177a2e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove : Global Vectors for Word Representation (Stanford)\n",
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d89cd6-cb5e-4e65-88d0-0146235deae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "corpus.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
