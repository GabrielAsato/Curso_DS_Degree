{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b2fd5a-e727-48e5-8bc2-d0cf6b0e2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d5174-708b-4a22-a1e6-d22ba1b1fb83",
   "metadata": {},
   "source": [
    "## CountVectorizer e TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b3cd8-496d-4f53-bd82-262c35dbe9a9",
   "metadata": {},
   "source": [
    "#### CountVectorizer\n",
    "\n",
    "Quando trabalhamos com dados em texto, precisamos representar como nuúmeros para que se possa ser entendido por máquinas. CountVectorizer é um método para converter texto em dados numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8d0c48-66dc-44cf-af0c-a8869ba86251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por exemplo\n",
    "text = \"Hello my name is James, this is my python notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17dde462-6a5c-4449-bd73-e148244cc568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is          2\n",
       "my          2\n",
       "Hello       1\n",
       "James,      1\n",
       "name        1\n",
       "notebook    1\n",
       "python      1\n",
       "this        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(text.split()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a428d8c-27d9-4c8e-be51-b3cffd0eaf80",
   "metadata": {},
   "source": [
    "Temos 8 palavras únicas no texto e oito colunas cada, representando uma única palavra na matriz. A linha representa contagem de palavras. Como 'is' e 'my' repetem duas vezes, temos a contagem de 2 para estes e 1 para o resto. CountVectorizer facilita para os dados em formato de texto ser usado diretamente em modelos de ML e DL para classificação de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ff6a365-cde6-408c-a3e4-adf0b92ce23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hello</th>\n",
       "      <th>big</th>\n",
       "      <th>count</th>\n",
       "      <th>create</th>\n",
       "      <th>dataset</th>\n",
       "      <th>differnt</th>\n",
       "      <th>features</th>\n",
       "      <th>james</th>\n",
       "      <th>name</th>\n",
       "      <th>notebook</th>\n",
       "      <th>of</th>\n",
       "      <th>python</th>\n",
       "      <th>this</th>\n",
       "      <th>try</th>\n",
       "      <th>trying</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hello  big  count  create  dataset  differnt  features  james  name  \\\n",
       "0      1    0      0       0        0         0         0      1     1   \n",
       "1      0    0      0       0        0         0         0      1     0   \n",
       "2      0    1      0       1        1         0         0      1     0   \n",
       "3      0    0      0       0        0         1         0      1     0   \n",
       "4      0    0      1       0        0         0         1      0     0   \n",
       "\n",
       "   notebook  of  python  this  try  trying  vectorizer  words  \n",
       "0         0   0       0     0    0       0           0      0  \n",
       "1         1   0       1     1    0       0           0      0  \n",
       "2         0   0       0     0    0       1           0      0  \n",
       "3         0   1       0     0    1       0           0      1  \n",
       "4         0   1       0     0    0       0           1      0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Hello my name is james',\n",
    "        'james this is my python notebook',\n",
    "        'james trying to create a big dataset',\n",
    "        'james of words to try differnt',\n",
    "        'features of count vectorizer']\n",
    "\n",
    "# modelo de ML\n",
    "count_vect = CountVectorizer(lowercase = False, stop_words = ['is', 'to', 'my']) # ou stop_words = 'english', max_df e min_df = frequência máxima e mínima, max_features\n",
    "# fit_transform(), fornece uma matriz mas sem as colunas\n",
    "count_matrix = count_vect.fit_transform(text)\n",
    "# transformar num array\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data = count_array, columns = count_vect.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afc75c46-50f5-4264-a68f-f96913649f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'big',\n",
       " 'count',\n",
       " 'create',\n",
       " 'dataset',\n",
       " 'differnt',\n",
       " 'features',\n",
       " 'james',\n",
       " 'name',\n",
       " 'notebook',\n",
       " 'of',\n",
       " 'python',\n",
       " 'this',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'vectorizer',\n",
       " 'words']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Somente as palavras que aparecem\n",
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bc3171f-8255-4855-bdb1-6c342f642d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hello': 0,\n",
       " 'name': 8,\n",
       " 'james': 7,\n",
       " 'this': 12,\n",
       " 'python': 11,\n",
       " 'notebook': 9,\n",
       " 'trying': 14,\n",
       " 'create': 3,\n",
       " 'big': 1,\n",
       " 'dataset': 4,\n",
       " 'of': 10,\n",
       " 'words': 16,\n",
       " 'try': 13,\n",
       " 'differnt': 5,\n",
       " 'features': 6,\n",
       " 'count': 2,\n",
       " 'vectorizer': 15}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Representa a posição da palavra na matriz\n",
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab236b-c50e-41b2-9a28-5cfe5c0d5123",
   "metadata": {},
   "source": [
    "CountVectorizer é somente um dos métodos para lidar com data em formato de texto. Outro seria o TD-IDF..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a5704-48e2-46ec-b23a-a159d024a882",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19fc9f-e5d0-4ddf-b9a7-25e83e561a4b",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "- Significa \"Term Frequency - Inverse Document Frequency\". é uma técnica que quantifica palavras em um conjunto de documentos. Geralmente, computamos um score para cada palavra para siginificar sua importância no corpus. Este método é amplamente utilizado em Retençao de Informação e Mineração de Texto.\n",
    "- t : termo (palavra), d : document (conjunto de palavras), N : contagem do corpus, corpus : o total do conjunto de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b27e5-2d82-43e0-8334-47da01be4dd2",
   "metadata": {},
   "source": [
    "##### Term Frequency (TF)\n",
    "- Mede a frequência da palavra em um documento. Depende altamente do comprimento (length) do documento e da generalidade da palavra (quão comum é uma palavra, como 'de'). Se um texto é mais longo que outro, algumas palavras mais genéricas aparecem mais nos textos longos que os curtos, por isso é feito normalização na frequência.\n",
    "- Quando vetorizamos um documento, não podemos só considerar as palavras que estão presentes num documento particular. Caso isso aconteça, é quase certeza que o comprimento será diferente e não podemos computar a similaridade. Nesse caso, computamos o documento em um **vocab**. Vocab é uma lista de todas as possíveis palavras no corpus.\n",
    "- Precisamos da contagem de palavras de todas as palavras do vocab e o comprimento do documento para computar TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d14ee-995c-42a4-871f-cb26c2ad161f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3954e748-e613-46b0-b3bd-3ec362b8bbab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb779c8-5d75-4933-9a28-97d9720476e6",
   "metadata": {},
   "source": [
    "Ref:\n",
    "- [1] https://towardsdatascience.com/basics-of-countvectorizer-e26677900f9c\n",
    "- [2] https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089#:~:text=TF%2DIDF%20stands%20for%20%E2%80%9CTerm,Information%20Retrieval%20and%20Text%20Mining."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
