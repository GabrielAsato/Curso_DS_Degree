{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3 - Regressão linear\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Regressão linear simples\n",
    "- 3) Regressão linear múltipla\n",
    "- 4) Overfitting: um dos lados do tradeoff viés-variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "Imagine que você quer vender sua casa.\n",
    "\n",
    "Você sabe os atributos da sua casa: quantos cômodos têm, quantos carros cabem na garagem, qual é a área construída, qual sua localidade, etc.\n",
    "\n",
    "Agora, a pergunta é: qual seria o melhor preço pra você colocá-la a venda, ou seja, quanto de fato ela vale?\n",
    "\n",
    "Você pode solicitar a avaliação de um corretor de imóveis (contando com a experiência dele), ou então...\n",
    "\n",
    "...fazer um modelo de **Machine Learning**, que, com base nos atributos e preços de diversas outras casas, pode fazer uma **predição** sobre o preço adequado da sua casa!\n",
    "\n",
    "Para resolver este problema, podemos utilizar um dos mais simples e importantes algoritmos de machine learning: a **Regressão Linear!**\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para introduzirmos as ideias, vamos usar um [dataset de preço de casas](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).\n",
    "\n",
    "Esta base de dados contém **79 features** (+ 1 ID), que são as características de cada uma das casas listadas; e **1 target**, que é o preço pelo qual aquela casa foi vendida.\n",
    "\n",
    "Por termos o target disponível, estamos trabalhando com um problema de **aprendizagem supervisionada**.\n",
    "\n",
    "Para o significado de cada uma das features, e os valores que elas podem assumir, veja a página acima.\n",
    "\n",
    "**Vamos ler a base e começar a explorá-la!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por enquanto, não vamos nos preocupar com os dados missing, pois vamos usar apenas uma feature no nosso modelo inicial.\n",
    "\n",
    "Aproveite para depois explorar os dados da forma que quiser!\n",
    "\n",
    "Por enquanto, vamos dar uma olhada na coluna target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomar o log de distribuições enviesadas tende a diminuir o desvio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fica evidente que a distribuição é desviada para a direita.\n",
    "\n",
    "Vamos tentar alterar isso na próximas versões do modelo para ver se teremos ganhos de performance!\n",
    "\n",
    "Por enquanto, seguimos assim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora dar uma olhada na correlação das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em particular, podemos olhar a correlação entre as features e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que a variável de área construída (\"GrLivArea\") é uma forte candidata a **explicar** o preço das casas, pois vemos calaramente uma correlação entre as variáveis!\n",
    "\n",
    "Mas note que há claramente dois outliers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora iniciar a construção de um modelo bem simples, que utilize a variável GrLivArea para predizer o preço!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Regressão linear simples\n",
    "\n",
    "Apesar de alguns outliers, parece bem adequado que os pontos plotados acima sejam descritos por uma reta, não é mesmo?\n",
    "\n",
    "Ou, melhor dizendo: **a variável GrLivArea parece estar relacionada ao target SalePrice linearmente!**\n",
    "\n",
    "Para modelarmos esta relação, vamos conhecer o modelo de **Regressão Linear Simples**.\n",
    "\n",
    "Como o próprio nome diz, o modelo de Regressão Linear será **uma reta (polinômio linear)**, que melhor se ajusta aos seus dados!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de **Regressão Linear Simples** será uma linha reta que relaciona Y (o preço da casa) e X (os atributos da casa). \n",
    "\n",
    "Se utilizarmos **apenas um atributo** (como, por exemplo, a área construída), temos uma **Regressão Linear Simples**, e nosso modelo é:\n",
    "\n",
    "$$ \\hat{y} = b_0 + b_1 X $$\n",
    "\n",
    "Neste caso, o modelo tem dois coeficientes (ou **parâmetros**) a serem determinados: $b_0$ (intercepto ou coeficiente linear) e $b_1$ (coeficiente angular). \n",
    "\n",
    "A equação acima exprime a **forma funcional** do conjunto de hipóteses com o qual trabalharemos: funções lineares, de uma úniva variável. Isto é,\n",
    "\n",
    "$$ f_{H, \\vec{b}} = b_0 + b_1 X $$\n",
    "\n",
    "Ou seja,\n",
    "\n",
    "$$ \\mathcal{H} = \\{ f_{H, \\vec{b}}\\} = \\{ b_0 + b_1 X \\} $$ \n",
    "\n",
    "é o conjunto de hipóteses que está sendo considerado, e o vetor de parâmetros é:\n",
    "\n",
    "$$\\vec{b} = \\begin{bmatrix}\n",
    "b_0\\\\ \n",
    "b_1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "O **algoritmo de aprendizagem** do estimador é utilizado justamente para encontrarmos os coeficientes $b_0$ e $b_1$ (isto é, o vetor de parâmetros) **que melhor se ajustam aos dados!**\n",
    "\n",
    "Para fazer isso, pode-se utilizar o método dos **mínimos quadrados** (OLS  - ordinary least squares) ou então o [gradiente descendente](https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931).\n",
    "\n",
    "Vamos conhecer o OLS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O algoritmo de aprendizagem da regressão linear\n",
    "\n",
    "De maneira esquemática, um algoritmo de aprendizagem recebe:\n",
    "\n",
    "- Um conjunto de hipóteses $\\mathcal{H}$;\n",
    "- Um conjunto de dados de treino $\\left(X_i, y_i \\right)$\n",
    "\n",
    "A partir destes inputs, o algoritmo constrói uma **função de perda**, que nada mais é que uma função que contabiliza **os erros cometidos pelo modelo**.\n",
    "\n",
    "E para sabermos o quanto um modelo está errando é muito simples: basta **compararmos o target predito $\\hat{y}$ com o target real $y$**!\n",
    "\n",
    "Isso pode ser feito de muitas maneiras. A \"maneira\" específica é o que determina a relação funcional da função de custo de interesse. Para regressão linear, a função de perda mais comum é o **erro quadrático (squared error)**:\n",
    "\n",
    "$$\\text{SE}= (y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "Onde $i = 1, 2, \\cdots, n$ é um índice que identifica cada uma das $n$ observações de treino.\n",
    "\n",
    "Obs.: se tomarmos a média do SE em toda a base de treino, temos o **Mean Squared Error** (MSE):\n",
    "\n",
    "$$\\text{MSE} = \\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "> Quando tomamos a função de erro para uma única observação, a chamamos de **função de perda**. Quando tomamos sua média sobre todo o dataset, a chamamos de **função de custo**. Na prática, os termos são usados como sinônimos (e, pro problema matemático a ser resolvido, tanto faz também)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://images.squarespace-cdn.com/content/v1/5acbdd3a25bf024c12f4c8b4/1600368657769-5BJU5FK86VZ6UXZGRC1M/Mean+Squared+Error.png width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, note uma coisa muito importante: **a função de custo é inteiramente dependente da função de hipótese (e, portanto, dos parâmetros!) e dos dados de treino!**\n",
    "\n",
    "De fato, para a i-ésima observação, $\\hat{y}_i = b_0 + b_1 X_i$ (note aqui a dependência da hipótese e dos dados!). Assim,\n",
    "\n",
    "$$(y_i-\\hat{y}_i)^2 = (y_i - (b_0 + b_1 X_i))^2 $$\n",
    "\n",
    "Por isso, escrevemos a função de custo como $\\mathcal{L}_{H, \\vec{b}}(X_i, y_i)$, para deixar claro que ela depende tanto dos dados $\\left(X_i, y_i \\right)$ quando da hipótese parametrizada:\n",
    "\n",
    "$$\\mathcal{L}_{H, \\vec{b}}(X_i, y_i) = \\sum_{i=1}^n(y_i - (b_0 + b_1 X_i))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que temos uma função de custo, nosso objetivo passa a ser **minimizá-la**. E isso faz total sentido: queremos que nosso modelo, após ter \"aprendido\", erre o mínimo possível!\n",
    "\n",
    "Por isso, naturalmente caímos em um **problema de otimização**. Mas, a pergunta que surge é: queremos minimizar o erro **com relação a que?**\n",
    "\n",
    "Agora, é importante lembrarmos que a **função hipótese é parametrizada**. E é justamente o vetor de parâmetros que determina **a reta que melhor se ajusta aos dados**. \n",
    "\n",
    "Assim, podemos resumir o objetivo do algoritmo de aprendizagem como:\n",
    "\n",
    "> Determinar o vetor de parâmetros que minimiza a função de custo nos dados de treino\n",
    "\n",
    "E isso faz total sentido, não é mesmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, operacionalmente, isso é justamente o que queremos fazer:\n",
    "\n",
    "$$\\hat{b} = \\operatorname*{argmin}_b \\left( \\mathcal{L}_{H, \\vec{b}}(X_i, y_i) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe uma forma muito conhecida e natural para resolvermos problemas de otimização como este: o famoso \"deriva e iguala a 0\".\n",
    "\n",
    "E é exatamente o que o método OLS nos dá: através da otimização explícita da função de custo quadrática, temos uma expressão analítica para os parâmetros:\n",
    "\n",
    "$$ \\left\\{\\begin{matrix}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_0} = 0\\\\ \n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_1} = 0\n",
    "\\end{matrix}\\right. \n",
    "\\Rightarrow\n",
    "\\left\\{\\begin{matrix}\n",
    "\\hat{b}_1 = \\frac{\\sum_i (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_i (x_i - \\bar{x})^2}\\\\ \n",
    "\\hat{b}_0 = \\bar{y} - \\hat{b}_1 \\bar{x}\n",
    "\\end{matrix}\\right. \\ ,\n",
    "$$\n",
    "\n",
    "onde: $\\bar{x} = \\frac{1}{n} \\sum_i x_i$ e $\\bar{y} = \\frac{1}{n} \\sum_i y_i$, são os valores médios da feature e target, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para quem quiser saber detalhes sobre o procedimento acima, sugiro as referências citadas, ou então [este artigo super simples](https://are.berkeley.edu/courses/EEP118/current/derive_ols.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E esse é o algoritmo de aprendizagem da regressão linear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 1 - construção do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos os dados, escolhemos o conjunto de hipóteses, e conhecemos também o algoritmo de treinamento da regressão linear!\n",
    "\n",
    "Felizmente, não precisamos implementar este algoritmo na mão (embora, caso queira, fique à vontade! É um ótimo exercício!)\n",
    "\n",
    "Aqui na aula, usaremos o sklearn para isso!\n",
    "\n",
    "Vamos começar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o modelo está treinado, podemos dar uma olhada nos coeficientes que foram encontrados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como interpretamos este resultado?\n",
    "\n",
    "O nosso modelo final é dado por:\n",
    "\n",
    "$$ \\hat{y} = \\mathcal{M} = f_{H, \\hat{\\vec{b}}}(x) =  1562.01 + 118.61 \\times \\text{GrLiveArea}$$\n",
    "\n",
    "Isto quer dizer que:\n",
    "\n",
    "> Aumentando a variável \"GrLiveArea\" em uma unidade faz com que o preço seja aumentado em USD 118.6!\n",
    "\n",
    "> O preço mínimo a ser pago, independente da área construída, é de 1562.01!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar o modelo treinado, neste caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É raro que consigamos visualizar nosso modelo final como fizemos acima, mas no caso da regressão linear simples, temos essa sorte! :)\n",
    "\n",
    "Vamos agora fazer algumas previsões!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou ainda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pedizendo vários valores de uma vez (muito mais comum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 2 - avaliação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos o modelo treinado e algumas previsões, como avaliamos a performance do modelo?\n",
    "\n",
    "Para isso, podemos dar uma olhada nos **resíduos** das predições! Os resíduos nada mais são do que**os erros do modelo**, ou seja, **a diferença entre cada valor predito e o valor real**, para **os dados de teste!** Isto é,\n",
    "\n",
    "$$R(y_i) = y_i - \\hat{y}_i $$\n",
    "\n",
    "$$R(y_i) + \\hat{y}_i= y_i  $$\n",
    "\n",
    "$$ \\hat{y}_i= y_i - R(y_i)  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O caso 100% ideal seria $y_i = \\hat{y}_i$, o que produziria uma reta exata!\n",
    "\n",
    "Quanto mais \"espalhados\" estiverem os pontos em torno da reta, em geral **pior é o modelo**, pois ele está errando mais!\n",
    "\n",
    "Uma forma de quantificar isso através de uma métrica conhecida como **$R^2$**, o **coeficiente de determinação**.\n",
    "\n",
    "Este coeficiente indica **o quão próximos os dados estão da reta ajustada**. Por outro lado, o $R^2$ representa a porcentagem de variação na resposta que é explicada pelo modelo.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}$$\n",
    "\n",
    "É possível utilizar o $R^2$ nos dados de treino, mas temos que tomar muito cuidado com a forma como interpretaremos esta métrica! Discutiremos mais a diante a importância de calcularmos as métricas de avaliação também na base de treino.\n",
    "\n",
    "Por enquanto, vamos calcular o $R^2$ nos dados de teste apenas, como faremos a seguir. Essa métrica equivale, portanto, **ao gráfico que fizemos acima!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra coisa importante é que os resíduos sejam **normalmente distribuídos**.\n",
    "\n",
    "Se esse não for o caso, é muito importante que você reveja se o modelo escolhido de fato é adequado ao seu problema!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além dos resíduos, existem três principais **métricas de avaliação** do modelo de regressão linear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error** (MAE) é a média do valor absoluto de todos os resíduos (erros):\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean Squared Error** (MSE) é a média dos erros quadrados:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root Mean Squared Error** (RMSE) é a raiz quadrada da média dos erros quadrados:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "Comparando as métricas:\n",
    "\n",
    "- **MAE** é a mais simples de entender, mas ela penaliza mais erros menores;\n",
    "- **MSE** é a métrica mais popular, pois essa métrica penaliza mais erros maiores, o que faz mais sentido em aplicações reais.\n",
    "- **RMSE** é ainda mais popular, pois esta métrica está nas mesmas unidades que o target.\n",
    "\n",
    "Estas métricas todas podem ser utilizadas como **funções de custo** a serem minimizadas pelo algoritmo do estimador.\n",
    "\n",
    "Inclusive, já conhecemos uma delas: O MSE, que é usado como função de custo para o OLS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em tudo junto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer algumas mudanças?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Regressão linear múltipla\n",
    "\n",
    "O modelo que fizemos acima considera uma única feature como preditora do preço da casa.\n",
    "\n",
    "Mas temos outras 78 dessas features! Será que não há mais informação útil em todas essas outras variáveis?\n",
    "\n",
    "Em geral, sim! É natural que esperemos que **mais variáveis** tragam **mais informações** ao modelo, e, portanto, o torne mais preciso!\n",
    "\n",
    "Para incorporar estas outras variáveis ao modelo, é muito simples! \n",
    "\n",
    "Podemos passar a utilizar outros atributos (como o número de cômodos, qual é a renda média da vizinhança, etc.), e neste caso teremos uma **Regressão Linear Múltipla**, que é expressa pela seguinte função de hipótese:\n",
    "\n",
    "$$ \\hat{y} = f_{H, \\vec{b}} = b_0 + b_1 X_1 + b_2 X_2 + \\cdots + b_n X_n $$\n",
    "\n",
    "Neste caso, além de $b_0$ e $b_1$, temos também outros coeficientes, um pra cada uma das $n$ features que escolhermos! Ou seja, o vetor de parâmetros tem $n+1$ dimensões:\n",
    "\n",
    "$$\\vec{b} = \\begin{bmatrix}\n",
    "b_0\\\\ \n",
    "b_1\\\\\n",
    "\\vdots\\\\\n",
    "b_n\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Modelos de regressão múltipla são potencialmente mais precisos, mas há também um lado ruim: nós perdemos a **possibilidade de visualização**. Agora, não temos mais uma reta, mas sim um **hiperplano** que relaciona todas as features com o target!\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1120/0*rGSfRsMjiQeG5jof.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O OLS também é válido para a regressão linear múltipla, mas o fato de termos muitas variáveis faz com que os cálculos do problema de otimização sejam consideravelmente mais complicados.\n",
    "\n",
    "Para facilitar este procedimento, é muito comum utilizarmos uma **notação matricial**, que facilita muitíssimo o cálculo do problema de otimização. Para os interessados, sugiro as referências, ou então [esta lecture](https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir esse modelo na prática com o sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observação: a coluna \"Id\" traz apenas um número de identificação arbitrário que não deve ser correlacionado com o target. Portanto, vamos desconsiderar esta coluna de nosso modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível calcularmos as métricas de performance na base de treino, mas temos que tomar muito cuidado ao interpretar estas medidas!\n",
    "\n",
    "Mais adiante falaremos sobre overfitting, e este ponto ficará mais claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando:\n",
    "\n",
    "```\n",
    "Métricas de avaliação (dados de teste):\n",
    "\n",
    "R^2: 0.8563506695017936\n",
    "MAE: 20734.90415410572\n",
    "MSE: 793479736.8905219\n",
    "RMSE: 28168.772371023235\n",
    "```\n",
    "\n",
    "```\n",
    "Métricas de avaliação (dados de treino):\n",
    "\n",
    "R^2: 0.8616841881921395\n",
    "MAE: 20508.039034548918\n",
    "MSE: 900886802.9866579\n",
    "RMSE: 30014.776410739058\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos olhar para os parâmetros do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível interpretar os parâmetros e atribuir uma \"importância\" de cada feature ao valor do respectivo parâmetro. Mas, cuidado: essa análise é afetada pela escala das features! Veja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma de eliminarmos o efeito da escala, é **escalando os dados** (um pré-processamento).\n",
    "\n",
    "Isso pode ser visto como uma terceira passada no ciclo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A performance do modelo melhorou?\n",
    "\n",
    "Será que dá pra melhorar mais?\n",
    "\n",
    "Opções:\n",
    "\n",
    "- tentar apenas um subconjunto de features: **feature selection**\n",
    "\n",
    "\n",
    "- passar a utilizar as features categóricas: **feature engeneering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Overfitting: um dos lados do tradeoff viés-variância\n",
    "\n",
    "O famoso **tradeoff viés-variância** é um dos conceitos mais importantes em apredizado de maquina.\n",
    "\n",
    "Muitas vezes alguns modelos têm 100% de acerto nos dados de **treino**, mas **na base de teste** a performance cai para menos de 50%.\n",
    "\n",
    "Isso pode acontecer porque o modelo fica **especialista apenas no conjunto de treino**, não conseguindo **generalizar os padrões para além dos dados vistos**. \n",
    "\n",
    "Quando isso ocorre, dizemos que nosso modelo sofre de **overfitting**.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\" width=800>\n",
    "\n",
    "O overfitting está intimamente ligado com o conceito de **viés** (bias) e **variância** (variance):\n",
    "\n",
    ">**Viés**<br>\n",
    "É a diferença entre o que o modelo prediz, e o valor correto a ser predito.<br>\n",
    "Modelos com alto viés são muito simples, de modo a **não conseguir capturar as relações que os dados de treino exibem** (underfit).<br>\n",
    "Issso faz com que ambos os erros de treino e de teste sejam altos.\n",
    "<br><br>\n",
    "Em outras palavras:<br>\n",
    "**Incapacidade de um modelo de capturar a verdadeira relação entre features e target**\n",
    "\n",
    "\n",
    "> **Variância**<br>\n",
    "Variância se refere à variabilidade das predições de um modelo.<br>\n",
    "Modelos com alta variância são muito complexos, por **aprenderem demais as relações  exibidas nos dados de treino** (overfit).<br>\n",
    "Isso faz com que os erros de treino sejam baixos, mas os erros de teste sejam altos.\n",
    "<br><br>\n",
    "Em outras palavras:<br>\n",
    "**Incapacidade de um modelo performar bem em outros datasets diferentes do usado no treinamento**. \n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2017/02/Bias-Variance-Tradeoff-In-Machine-Learning-1.png\" width=500>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1494/1*C7ZKM93QVdpeSCGbF5TjIg.png\" width=800>\n",
    "\n",
    "Para demonstrar overfit ser usado o conjuto de teste [anscombe](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos supor que este dado represente valores de medições de um sensor, porém o sensor teve um pequeno problema durante a medição.\n",
    "\n",
    "Podemos perceber facilmente qual é este erro, e qual seria a função de regreesão para este sensor com os dados validos: **regressão linear**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que a função linear encontrar já aprensenta um padrão muito similiar aos dados, porém um ponto error faz com que ela não tenha um resultado otimo.\n",
    "\n",
    "Podemos utilizar regressões polinomiais, que possuem ordem maiores que 1, para tentar diminuir o erro da regressão. Por exemplo, podemos considerar um polinômio de grau 6,\n",
    "\n",
    "$$\\hat{y}_{i} = \\beta_{1} + \\beta_{2} x_{i} + \\beta_{3} {x_{i}}^{2} + \\cdots + \\beta_{6} {x_{i}}^{6}$$\n",
    "\n",
    "Para criar modelos polinomiais com o sklearn, [dê uma olhada aqui](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html). Mas, teremos uma aula sobre isso, logo logo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao utilizarmos uma regressão de ordem 6 percebemos que ela se ajusta ao valor com erro, porém ela **se distancia da regressão que realmente representa os dados**. \n",
    "\n",
    "Tentar **aprender o erro faz com ela com ela não aprenda a função real**. \n",
    "\n",
    "Isto acontece pois ela se **super ajustou aos dados de treino, se distanciando dos dados reais**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Como garantir que nosso modelo não está sofrendo de overfitting?__\n",
    "\n",
    "Naturalmente, essa é uma pergunta de extrema importância, especialmente no contexto de **redes neurais**. [Veja aqui](https://towardsdatascience.com/8-simple-techniques-to-prevent-overfitting-4d443da2ef7d) e [aqui](https://towardsdatascience.com/dont-overfit-how-to-prevent-overfitting-in-your-deep-learning-models-63274e552323) algumas discussões.\n",
    "\n",
    "Na prática: **jamais se apegue à peformance de treino como forma de avaliar o modelo!** O que queremos otimizar sempre será a performance **avaliada nos dados de teste**, isto é, a **performance de generalização** do modelo. \n",
    "\n",
    "Assim, é **avaliando o modelo nos dados de teste** que garantimos que uma boa performance não é produto do overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais a diante, discutiremos overfitting e o tradeoff viés/variância em detalhes. Por enquanto, uma boa prática é comparar as métricas de treino com as métricas de teste, conforme fizemos acima. Isso nos permite avaliar, de maneira rápida e simples, se houve underfitting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
