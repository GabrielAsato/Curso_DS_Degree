{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 5 - Espaços de features polinomiais - aumentando a complexidade de hipóteses\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Espaços de features polinomiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:58:56.532932Z",
     "start_time": "2022-04-29T16:58:56.472965Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:58:59.518634Z",
     "start_time": "2022-04-29T16:58:56.537930Z"
    }
   },
   "outputs": [],
   "source": [
    "from ml_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:58:59.628948Z",
     "start_time": "2022-04-29T16:58:59.518634Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "## 1) Espaços de features polinomiais\n",
    "\n",
    "Muitas vezes, temos dados que simplesmente não se ajustam às hipóteses simples, lineares, que conhecemos até o momento.\n",
    "\n",
    "Quando isso acontece, é muito provável que soframos **underfitting**, pois uma forma funcional demasiadamente simples de uma hipótese pode não ser capaz de capturar o comportamento de uma função teórica $\\mathcal{F}$ mais complexa, conforme refletido pela amostra.\n",
    "\n",
    "Nestes casos, a solução é simples: basta escolhermos hipóteses mais complexas!\n",
    "\n",
    "Pra começar nosso estudo, vamos utilizar dados artificiais bem simples: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:58:59.929230Z",
     "start_time": "2022-04-29T16:58:59.631948Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "N = 100\n",
    "X = np.random.uniform(-1.5, 1.5, N)\n",
    "\n",
    "b0, b1, b2, b3, b4 = 1, 0.1, -0.02, 0.01, 0.5\n",
    "y = b0 + b1*X + b2*(X**2) + b3*(X**2) + b4*(X**4) + np.random.normal(0, 0.4, N)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos com uma única feature, vamos aplicar o reshape já agora!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos fazer uma regressão linear..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente, temos métricas bem ruins, dada a escolha ruim de hipótese!\n",
    "\n",
    "Hipótese atual:\n",
    "\n",
    "$$f_{h, \\  \\vec{b}}(x) = b_0 + b_1x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer algo melhor: como nossos dados são aproximadamente quadráticos, faria sentido escolher uma **hipótese quadrática**, não é mesmo? Isto é,\n",
    "\n",
    "$$f_{h, \\  \\vec{b}}(x) = b_0 + b_1x + b_2x^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E é aqui que entra um dos aspectos mais importantes de um modelo linear como a regressão linear: **o modelo é linear nos parâmetros, não necessariamente nas features!**\n",
    "\n",
    "Ou seja, o termo quadrático que incluímos **pode ser considerado como uma nova feature linear**. Para ver isso, basta definir $z \\equiv x^2$, que voltamos a ter uma hipótese linear, mas agora em duas variáveis:\n",
    "\n",
    "$$f_{h, \\  \\vec{b}}(x, z) = b_0 + b_1x + b_2z$$\n",
    "\n",
    "Ou seja, ainda temos uma regressão linear (múltipla, agora).\n",
    "\n",
    "E isso é verdade para **qualquer** combinação de features que possamos criar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "Um outro exemplo: considere uma hipótese linear para um modelo com duas features $x_1, x_2$:\n",
    "\n",
    "$$f_{h, \\  \\vec{b}}(x_1, x_2) = b_0 + b_1x_1 + b_2x_2$$\n",
    "\n",
    "Caso queiramos produzir um modelo quadrático, temos que incluir os termos $x_1^2, x_2^2$ e também $x_1x_2$ (que também é quadrático), de modo que nossa hipótese fica sendo:\n",
    "\n",
    "$$f_{h, \\  \\vec{b}}(x_1, x_2) = b_0 + b_1x_1 + b_2x_2 + b_3 x_1^2 + b_4 x_2^2 + b_5 x_1 x_2$$\n",
    "\n",
    "O que não deixa de ser uma **regressão linear múltipla** de 5 variáveis ($x_3 \\equiv x_1^2$, $x_4 \\equiv x_2^2$ e $x_5 \\equiv x_1x_2$):\n",
    "\n",
    "$$f_{h, \\  \\vec{b}}(x_1, x_2, x_3, x_4, x_5) = b_0 + b_1x_1 + b_2x_2 + b_3 x_3 + b_4 x_4 + b_5 x_5$$\n",
    "\n",
    "E assim por diante! ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, para criarmos um modelo quadrático para nossos dados, bastaria criarmos uma nova feature $z = x^2$, e passar apenas esta nova feature para o  modelo de regressão linear **simples**. Isso equivale a usar uma hipótese $$f_{h, \\  \\vec{b}}(z) = b_0 + b_1z = b_0 + b_1x^2$$\n",
    "\n",
    "Vejamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No espaço transformado, esse foi o modelo treinado:\n",
    "\n",
    "$f_{h, \\  \\vec{b}}(z) = b_0 + b_1z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, no espaço original, o modelo foi esse:\n",
    "\n",
    "$f_{h, \\  \\vec{b}}(x) = b_0 + b_1x^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim, um modelo beeem melhor!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E se quisermos usar a hipótese quadrática mais completa, com ambos os termos linear e quadrático? (Isto é, $f_{h, \\  \\vec{b}}(x) = b_0 + b_1x + b_2x^2$)\n",
    "\n",
    "Bem simples: basta passarmos as duas features pro sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No espaço transformado, treinaríamos o seguinte modelo:\n",
    "\n",
    "$f_{h, \\  \\vec{b}}(x, z) = b_0 + b_1x + b_2z$\n",
    "\n",
    "Isso é um plano!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, no espaço original, o modelo projetado seria esse:\n",
    "\n",
    "$f_{h, \\  \\vec{b}}(x) = b_0 + b_2x + b_2x^2$\n",
    "\n",
    "Uma hipótese quadrática genérica!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:59:02.603863Z",
     "start_time": "2022-04-29T16:59:02.421969Z"
    }
   },
   "outputs": [],
   "source": [
    "# treinar o modelo em casa \"manualmente\", caso queira\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, lembre que geramos os dados de acordo com um processo teório de grau 4! Então, seria legal que nossa hipótese tbm fosse de grau 4, nao é mesmo?\n",
    "\n",
    "E isso é possível!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No geral, dá pra ir aumentando a ordem dos polinomios criando features de ordem maior uma a uma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aí, bastaria utilizar este df pra treinar o modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:59:03.025638Z",
     "start_time": "2022-04-29T16:59:02.874708Z"
    }
   },
   "outputs": [],
   "source": [
    "# treinar o modelo em casa \"manualmente\", caso queira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas esse é um procedimento bem manual. Pra nossa sorte, o sklearn existe, e uma de suas muitas ferramentas especiais para machine learning (no caso, pré-processamento) é o [polynomial features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html), que permite a criação de toda as combinações polinomiais de features automaticamente!\n",
    "\n",
    "O PolynomialFeatures é nosso primeiro exemplo de **transformer** do sklearn - um método cujo objetivo é aplicar alguma **transformação** aos dados. Veremos vários outros exemplos de transformers durante o curso.\n",
    "\n",
    "Em particular, todos os transformers se comportam como se fossem \"estimadores\", no sentido de que eles devem \n",
    "ser \"ajustados\" aos dados -- por isso, eles também têm o método `.fit()` -- que ajusta o transformer aos dados; além do método `.transform()`, que efetivamente transforma os dados. Existe também o `.fit_transform()`, que faz as duas coisas ao mesmo tempo -- mas vamos evitar de usá-lo, por motivos que ficarão claros no futuro próximo (data leakage).\n",
    "\n",
    "Lembre-se de fitar o transformados sempre nos dados de treino, apenas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos o uso da classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos generalizar nosss funções (veja no .py a definição da nova função `reg_lin_poly_features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em aulas anteriores, discutimos sobre a **maldição da dimensionalidade**, e como é fácil overfitar um modelo ao aumentarmos a dimensionalidade (dado o correspondente aumento da complexidade da hipótese).\n",
    "\n",
    "Vamos ver isso claramente, e fazer o plot do tradeoff viés-variância?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "_____________\n",
    "_____________\n",
    "\n",
    "Agora que já entendemos a técnica em um dataset bem simples, vamos voltar pra um dataset real!\n",
    "\n",
    "Vamos voltar pros dados da precificação de casas -- ali, o poly_features se mostrará ainda mais útil!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:59:13.378242Z",
     "start_time": "2022-04-29T16:59:13.221615Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/house_prices.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Id\", \"SalePrice\"])\n",
    "y = df[\"SalePrice\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_model = X_train.select_dtypes(include=np.number).dropna(axis=\"columns\")\n",
    "X_test_model = X_test.loc[:, X_train_model.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estes dois últimos modelos têm muuuuuito mais parametros que observações, portanto, aprenderam perfeitamente até mesmo os ruidos da base de treino!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T01:14:14.508900Z",
     "start_time": "2022-01-28T01:14:14.485892Z"
    }
   },
   "source": [
    "**Claro overfitting!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossas hipóteses foram:\n",
    "\n",
    "$$ f_{H, \\vec{b}}(\\vec{x}) = b_0 + b_1x_1 + b_2x_2 + \\cdots + b_{594} x_{594}$$\n",
    "\n",
    "pro primeiro modelo (features quadráticas); e, para o segundo (features cúbicas):\n",
    "\n",
    "$$ f_{H, \\vec{b}}(\\vec{x}) = b_0 + b_1x_1 + b_2x_2 + \\cdots + b_{7139} x_{7139}$$\n",
    "\n",
    "Ou seja, temos um modelo **com muitos parâmetros**, ou seja, **muito complexo!**\n",
    "\n",
    "Com tantos parâmetros assim, há muitos **graus de liberdade** pra que a hipótese se ajuste até às particularidades da base de treino... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado é evidente: temos um modelo altamente **overfitado**, dado o número enorme de features após o transformer -- e isso porque estamos utilizando apenas features quadráticas e cúbicas, imagine se tivéssemos usado features de grau maior!\n",
    "\n",
    "É de se imaginar que muitas destas features não deveriam estar aí, não é mesmo?\n",
    "\n",
    "Oras, uma forma interessante de eliminar features é fazendo o que chamamos de **feature selection**.\n",
    "\n",
    "A ideia é a seguinte: gostaríamos sim de introduzir features polinomiais, aumentando um pouco a complexidade da hipótese, **mas não tanto!**. \n",
    "\n",
    "E é isso que conseguiremos fazer com as técnicas de **regularização**, que aprenderemos na próxima aula!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249.667px",
    "width": "359.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
